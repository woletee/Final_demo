{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age gender preferred_location preferred_hotel_type  \\\n",
      "0        1   34      F              beach               luxury   \n",
      "1        2   55      F        city center               budget   \n",
      "2        3   20      M        city center               budget   \n",
      "3        4   53      M              beach               budget   \n",
      "4        5   64      F              beach             boutique   \n",
      "\n",
      "   avg_rating_given  \n",
      "0          4.000708  \n",
      "1          4.890188  \n",
      "2          4.444119  \n",
      "3          4.742092  \n",
      "4          4.733793  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to create synthetic user profiles\n",
    "def create_user_profiles(num_users):\n",
    "    user_profiles = []\n",
    "    for user_id in range(1, num_users + 1):\n",
    "        user_profiles.append({\n",
    "            'user_id': user_id,\n",
    "            'age': random.randint(18, 70),\n",
    "            'gender': random.choice(['M', 'F']),\n",
    "            'preferred_location': random.choice(['beach', 'city center', 'mountain']),\n",
    "            'preferred_hotel_type': random.choice(['luxury', 'budget', 'boutique']),\n",
    "            'avg_rating_given': random.uniform(3.0, 5.0)\n",
    "        })\n",
    "    return pd.DataFrame(user_profiles)\n",
    "\n",
    "# Create 100 synthetic user profiles\n",
    "user_profiles = create_user_profiles(100)\n",
    "print(user_profiles.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  hotel_id  viewed  clicked    rating  booked\n",
      "0       66        17       0        0  2.099695       1\n",
      "1       72         7       0        0       NaN       0\n",
      "2       17         4       0        0  3.902601       0\n",
      "3        7         7       0        0       NaN       1\n",
      "4       45        10       1        1       NaN       0\n"
     ]
    }
   ],
   "source": [
    "# Define a function to simulate user interactions with hotels\n",
    "def simulate_interactions(user_profiles, hotel_data, num_interactions):\n",
    "    interactions = []\n",
    "    for _ in range(num_interactions):\n",
    "        user = user_profiles.sample(1).iloc[0]\n",
    "        hotel = hotel_data.sample(1).iloc[0]\n",
    "        interaction = {\n",
    "            'user_id': user['user_id'],\n",
    "            'hotel_id': hotel['hotel_id'],\n",
    "            'viewed': random.choice([0, 1]),\n",
    "            'clicked': random.choice([0, 1]),\n",
    "            'rating': random.uniform(1.0, 5.0) if random.choice([0, 1]) else None,\n",
    "            'booked': random.choice([0, 1])\n",
    "        }\n",
    "        interactions.append(interaction)\n",
    "    return pd.DataFrame(interactions)\n",
    "\n",
    "# Example hotel data (replace with your scraped data)\n",
    "hotel_data = pd.DataFrame({\n",
    "    'hotel_id': range(1, 21),\n",
    "    'name': [f'Hotel {i}' for i in range(1, 21)],\n",
    "    'location': random.choices(['beach', 'city center', 'mountain'], k=20),\n",
    "    'price_per_night': random.choices(range(50, 500, 50), k=20),\n",
    "    'star_rating': random.choices(range(1, 6), k=20),\n",
    "    'amenities': [random.choices(['Wi-Fi', 'Breakfast included', 'Swimming pool'], k=3) for _ in range(20)]\n",
    "})\n",
    "\n",
    "# Simulate 1000 user interactions\n",
    "interactions = simulate_interactions(user_profiles, hotel_data, 1000)\n",
    "print(interactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m\n\u001b[0;32m     19\u001b[0m hotel_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotel_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m21\u001b[39m),\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHotel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m21\u001b[39m)],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamenities\u001b[39m\u001b[38;5;124m'\u001b[39m: [random\u001b[38;5;241m.\u001b[39mchoices([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWi-Fi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakfast included\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSwimming pool\u001b[39m\u001b[38;5;124m'\u001b[39m], k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m)]\n\u001b[0;32m     26\u001b[0m })\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Simulate 1000 user interactions\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m interactions \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_interactions\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_profiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhotel_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(interactions\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36msimulate_interactions\u001b[1;34m(user_profiles, hotel_data, num_interactions)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_interactions):\n\u001b[0;32m      5\u001b[0m     user \u001b[38;5;241m=\u001b[39m user_profiles\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m     hotel \u001b[38;5;241m=\u001b[39m \u001b[43mhotel_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m     interaction \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m: user[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotel_id\u001b[39m\u001b[38;5;124m'\u001b[39m: hotel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotel_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbooked\u001b[39m\u001b[38;5;124m'\u001b[39m: random\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     14\u001b[0m     }\n\u001b[0;32m     15\u001b[0m     interactions\u001b[38;5;241m.\u001b[39mappend(interaction)\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py:5858\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   5855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5856\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[1;32m-> 5858\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5859\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   5861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\sample.py:151\u001b[0m, in \u001b[0;36msample\u001b[1;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define a function to simulate user interactions with hotels\n",
    "def simulate_interactions(user_profiles, hotel_data, num_interactions):\n",
    "    interactions = []\n",
    "    for _ in range(num_interactions):\n",
    "        user = user_profiles.sample(1).iloc[0]\n",
    "        hotel = hotel_data.sample(1).iloc[0]\n",
    "        interaction = {\n",
    "            'user_id': user['user_id'],\n",
    "            'hotel_id': hotel['hotel_id'],\n",
    "            'viewed': random.choice([0, 1]),\n",
    "            'clicked': random.choice([0, 1]),\n",
    "            'rating': random.uniform(1.0, 5.0) if random.choice([0, 1]) else None,\n",
    "            'booked': random.choice([0, 1])\n",
    "        }\n",
    "        interactions.append(interaction)\n",
    "    return pd.DataFrame(interactions)\n",
    "\n",
    "# Example hotel data (replace with your scraped data)\n",
    "hotel_data = pd.DataFrame({\n",
    "    'hotel_id': range(1, 21),\n",
    "    'name': [f'Hotel {i}' for i in range(1, 21)],\n",
    "    'location': random.choices(['beach', 'city center', 'mountain'], k=20),\n",
    "    'price_per_night': random.choices(range(50, 500, 50), k=20),\n",
    "    'star_rating': random.choices(range(1, 6), k=20),\n",
    "    'amenities': [random.choices(['Wi-Fi', 'Breakfast included', 'Swimming pool'], k=3) for _ in range(20)]\n",
    "})\n",
    "\n",
    "# Simulate 1000 user interactions\n",
    "interactions = simulate_interactions(user_profiles, hotel_data, 1000)\n",
    "print(interactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  hotel_id  viewed  clicked    rating  booked  age gender  \\\n",
      "0       64         2       0        0       NaN       1   36      M   \n",
      "1       64         2       0        0  3.778714       0   36      M   \n",
      "2       67         2       1        1       NaN       1   36      F   \n",
      "3       73         2       0        0       NaN       0   58      F   \n",
      "4       73         2       1        1  1.182294       1   58      F   \n",
      "\n",
      "  preferred_location preferred_hotel_type  avg_rating_given     name  \\\n",
      "0        city center               budget          3.831872  Hotel 2   \n",
      "1        city center               budget          3.831872  Hotel 2   \n",
      "2        city center               budget          4.003608  Hotel 2   \n",
      "3        city center             boutique          4.710647  Hotel 2   \n",
      "4        city center             boutique          4.710647  Hotel 2   \n",
      "\n",
      "      location  price_per_night  star_rating  \\\n",
      "0  city center              100            3   \n",
      "1  city center              100            3   \n",
      "2  city center              100            3   \n",
      "3  city center              100            3   \n",
      "4  city center              100            3   \n",
      "\n",
      "                                    amenities  \n",
      "0  [Wi-Fi, Swimming pool, Breakfast included]  \n",
      "1  [Wi-Fi, Swimming pool, Breakfast included]  \n",
      "2  [Wi-Fi, Swimming pool, Breakfast included]  \n",
      "3  [Wi-Fi, Swimming pool, Breakfast included]  \n",
      "4  [Wi-Fi, Swimming pool, Breakfast included]  \n"
     ]
    }
   ],
   "source": [
    "# Combine user profiles and interactions with hotel data\n",
    "combined_data = interactions.merge(user_profiles, on='user_id').merge(hotel_data, on='hotel_id')\n",
    "print(combined_data.head())\n",
    "\n",
    "# Preprocess the combined data (handle missing values, encode features, etc.)\n",
    "combined_data['rating'] = combined_data['rating'].fillna(combined_data['rating'].mean())\n",
    "# Further preprocessing steps as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9709  0.8063  0.8192  0.8396  0.9233  0.8719  0.0641  \n",
      "MAE (testset)     0.6932  0.5565  0.5802  0.5713  0.6624  0.6127  0.0545  \n",
      "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "user: 1          item: 1          r_ui = None   est = 3.03   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Prepare data for Surprise library\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(combined_data[['user_id', 'hotel_id', 'rating']], reader)\n",
    "\n",
    "# Use Singular Value Decomposition (SVD) for collaborative filtering\n",
    "svd = SVD()\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Predict ratings for a user (user_id = 1) for a hotel (hotel_id = 1)\n",
    "prediction = svd.predict(uid=1, iid=1)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8383  0.7986  0.9264  0.8932  0.8431  0.8599  0.0448  \n",
      "MAE (testset)     0.5929  0.5445  0.6709  0.6399  0.5912  0.6079  0.0436  \n",
      "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "user: 1          item: 1          r_ui = None   est = 3.09   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Define a function to create synthetic user profiles\n",
    "def create_user_profiles(num_users):\n",
    "    user_profiles = []\n",
    "    for user_id in range(1, num_users + 1):\n",
    "        user_profiles.append({\n",
    "            'user_id': user_id,\n",
    "            'age': random.randint(18, 70),\n",
    "            'gender': random.choice(['M', 'F']),\n",
    "            'preferred_location': random.choice(['beach', 'city center', 'mountain']),\n",
    "            'preferred_hotel_type': random.choice(['luxury', 'budget', 'boutique']),\n",
    "            'avg_rating_given': random.uniform(3.0, 5.0)\n",
    "        })\n",
    "    return pd.DataFrame(user_profiles)\n",
    "\n",
    "# Create 100 synthetic user profiles\n",
    "user_profiles = create_user_profiles(100)\n",
    "\n",
    "# Example hotel data (replace with your scraped data)\n",
    "hotel_data = pd.DataFrame({\n",
    "    'hotel_id': range(1, 21),\n",
    "    'name': [f'Hotel {i}' for i in range(1, 21)],\n",
    "    'location': random.choices(['beach', 'city center', 'mountain'], k=20),\n",
    "    'price_per_night': random.choices(range(50, 500, 50), k=20),\n",
    "    'star_rating': random.choices(range(1, 6), k=20),\n",
    "    'amenities': [random.choices(['Wi-Fi', 'Breakfast included', 'Swimming pool'], k=3) for _ in range(20)]\n",
    "})\n",
    "\n",
    "# Define a function to simulate user interactions with hotels\n",
    "def simulate_interactions(user_profiles, hotel_data, num_interactions):\n",
    "    interactions = []\n",
    "    for _ in range(num_interactions):\n",
    "        user = user_profiles.sample(1).iloc[0]\n",
    "        hotel = hotel_data.sample(1).iloc[0]\n",
    "        interaction = {\n",
    "            'user_id': user['user_id'],\n",
    "            'hotel_id': hotel['hotel_id'],\n",
    "            'viewed': random.choice([0, 1]),\n",
    "            'clicked': random.choice([0, 1]),\n",
    "            'rating': random.uniform(1.0, 5.0) if random.choice([0, 1]) else None,\n",
    "            'booked': random.choice([0, 1])\n",
    "        }\n",
    "        interactions.append(interaction)\n",
    "    return pd.DataFrame(interactions)\n",
    "\n",
    "# Simulate 1000 user interactions\n",
    "interactions = simulate_interactions(user_profiles, hotel_data, 1000)\n",
    "\n",
    "# Combine user profiles and interactions with hotel data\n",
    "combined_data = interactions.merge(user_profiles, on='user_id').merge(hotel_data, on='hotel_id')\n",
    "\n",
    "# Preprocess the combined data (handle missing values, encode features, etc.)\n",
    "combined_data['rating'] = combined_data['rating'].fillna(combined_data['rating'].mean())\n",
    "\n",
    "# Prepare data for Surprise library\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(combined_data[['user_id', 'hotel_id', 'rating']], reader)\n",
    "\n",
    "# Use Singular Value Decomposition (SVD) for collaborative filtering\n",
    "svd = SVD()\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Predict ratings for a user (user_id = 1) for a hotel (hotel_id = 1)\n",
    "prediction = svd.predict(uid=1, iid=1)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: HTTPSConnectionPool(host='www.tripadvisor.com', port=443): Max retries exceeded with url: /Hotel_Review-g187791-d203127-Reviews-Hotel_Delle_Nazioni-Rome_Lazio.html (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='www.tripadvisor.com', port=443): Read timed out. (read timeout=30)\"))\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# Function to scrape hotel reviews from TripAdvisor\n",
    "def scrape_tripadvisor_hotel_reviews(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "    \n",
    "    # Retry mechanism\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=5,\n",
    "        read=5,\n",
    "        connect=5,\n",
    "        backoff_factor=0.3,\n",
    "        status_forcelist=(500, 502, 504)\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    \n",
    "    try:\n",
    "        page = session.get(url, headers=headers, timeout=30)  # Increase the timeout duration\n",
    "        page.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if the request fails\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    reviews = []\n",
    "    \n",
    "    # Attempt to find the hotel name\n",
    "    hotel_name_tag = soup.find('h1')\n",
    "    hotel_name = hotel_name_tag.text if hotel_name_tag else 'Unknown Hotel'\n",
    "\n",
    "    # Attempt to find the review containers\n",
    "    review_containers = soup.find_all('div', class_='review-container')\n",
    "    \n",
    "    if not review_containers:\n",
    "        print(f\"No reviews found on page: {url}\")\n",
    "    \n",
    "    for review in review_containers:\n",
    "        try:\n",
    "            user_id = review.find('div', class_='info_text pointer_cursor').text.strip()\n",
    "            rating_class = review.find('span', class_='ui_bubble_rating')['class']\n",
    "            rating = int(rating_class[1].split('_')[1]) / 10\n",
    "            review_title = review.find('a', class_='title').text.strip()\n",
    "            review_text = review.find('q', class_='IRsGHoPm').text.strip()\n",
    "\n",
    "            review_data = {\n",
    "                'hotel_name': hotel_name,\n",
    "                'user_id': user_id,\n",
    "                'rating': rating,\n",
    "                'review_title': review_title,\n",
    "                'review_text': review_text,\n",
    "            }\n",
    "            reviews.append(review_data)\n",
    "        except AttributeError as e:\n",
    "            print(f\"Error parsing review: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(reviews)\n",
    "\n",
    "# Example URL of a TripAdvisor hotel page\n",
    "url = 'https://www.tripadvisor.com/Hotel_Review-g187791-d203127-Reviews-Hotel_Delle_Nazioni-Rome_Lazio.html'\n",
    "hotel_reviews = scrape_tripadvisor_hotel_reviews(url)\n",
    "print(hotel_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize the WebDriver (Ensure you have the correct driver for your browser installed)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/path/to/chromedriver\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_review_data\u001b[39m(url):\n\u001b[0;32m     10\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Initialize the WebDriver (Ensure you have the correct driver for your browser installed)\n",
    "driver = webdriver.Chrome(executable_path='/path/to/chromedriver')\n",
    "\n",
    "def get_review_data(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "    reviews = []\n",
    "    review_elements = driver.find_elements(By.CLASS_NAME, 'review-container')\n",
    "\n",
    "    for review_element in review_elements:\n",
    "        review = {}\n",
    "        try:\n",
    "            review['title'] = review_element.find_element(By.CLASS_NAME, 'noQuotes').text\n",
    "        except:\n",
    "            review['title'] = 'N/A'\n",
    "        \n",
    "        try:\n",
    "            review['rating'] = review_element.find_element(By.CSS_SELECTOR, 'span.ui_bubble_rating').get_attribute('class').split('_')[-1]\n",
    "        except:\n",
    "            review['rating'] = 'N/A'\n",
    "        \n",
    "        try:\n",
    "            review['text'] = review_element.find_element(By.CLASS_NAME, 'IRsGHoPm').text\n",
    "        except:\n",
    "            review['text'] = 'N/A'\n",
    "        \n",
    "        try:\n",
    "            user_info = review_element.find_element(By.CLASS_NAME, 'info_text')\n",
    "            review['username'] = user_info.find_element(By.CLASS_NAME, 'username').text\n",
    "            review['location'] = user_info.find_element(By.CLASS_NAME, 'userLoc').text\n",
    "            review['contributions'] = user_info.find_element(By.CLASS_NAME, 'badgetext').text\n",
    "        except:\n",
    "            review['username'] = 'N/A'\n",
    "            review['location'] = 'N/A'\n",
    "            review['contributions'] = 'N/A'\n",
    "\n",
    "        reviews.append(review)\n",
    "    return reviews\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    keys = data[0].keys()\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data)\n",
    "\n",
    "# Main function to scrape review data\n",
    "def main():\n",
    "    url = 'https://www.tripadvisor.com/Hotel_Review-g60763-d93603-Reviews-Hotel_Pennsylvania-New_York_City_New_York.html'  # Update this URL pattern\n",
    "    all_reviews = []\n",
    "\n",
    "    for page in range(0, 10):  # Adjust range and step as needed for more pages\n",
    "        page_url = f\"{url}?page={page+1}\"\n",
    "        reviews = get_review_data(page_url)\n",
    "        all_reviews.extend(reviews)\n",
    "        time.sleep(2)  # Sleep to avoid being blocked\n",
    "\n",
    "    # Save all reviews data\n",
    "    save_to_csv(all_reviews, 'reviews_data.csv')\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users DataFrame:\n",
      "   user_id  age gender preferred_location preferred_hotel_type\n",
      "0        1   40      M           mountain               luxury\n",
      "1        2   28      F           mountain               budget\n",
      "2        3   26      F        countryside               luxury\n",
      "3        4   38      M              beach               budget\n",
      "4        5   25      F        city center               luxury\n",
      "\n",
      "Hotels DataFrame:\n",
      "   hotel_id            hotel_name  \\\n",
      "0         1    A.C.C Design Hotel   \n",
      "1         2             Dasomchae   \n",
      "2         3       Brown Dot Hotel   \n",
      "3         4  Empire Tourist Hotel   \n",
      "4         5              CS Hotel   \n",
      "\n",
      "                                         description     city      country  \\\n",
      "0                 A modern hotel with stylish decor.  Gwangju  South Korea   \n",
      "1  A cozy hotel offering traditional Korean hospi...  Gwangju  South Korea   \n",
      "2      A comfortable hotel in a convenient location.  Gwangju  South Korea   \n",
      "3  An affordable hotel for budget-conscious trave...  Gwangju  South Korea   \n",
      "4           A hotel known for its excellent service.  Gwangju  South Korea   \n",
      "\n",
      "                                             address price  rating  \n",
      "0  226-11, Geumnam-ro, Dong-gu, Gwangju 61482 Sou...  None     4.0  \n",
      "1  27, Naesang-ro 51beon-gil, Gwangsan-gu, Gwangj...  None     4.5  \n",
      "2  5-8, Sangmujungang-ro 38beon-gil, Seo-gu, Gwan...  None     3.5  \n",
      "3  25, Imbangul-daero 800beon-gil, Gwangsan-gu, G...  None     3.0  \n",
      "4  128, Sangmupyeonghwa-ro, Seo-gu, Gwangju 61964...  None     3.5  \n",
      "\n",
      "Reviews DataFrame:\n",
      "   review_id  user_id  hotel_id  rating                review_txt\n",
      "0          1       77         2    2.09  Review text for review_1\n",
      "1          2       89         2    3.41  Review text for review_2\n",
      "2          3       87         1    4.41  Review text for review_3\n",
      "3          4       43         3    4.52  Review text for review_4\n",
      "4          5       35         5    2.50  Review text for review_5\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Provided hotel data\n",
    "hotels_data = [\n",
    "    {\"hotel_id\": 1, \"hotel_name\": \"A.C.C Design Hotel\", \"description\": \"A modern hotel with stylish decor.\", \"city\": \"Gwangju\", \"country\": \"South Korea\", \"address\": \"226-11, Geumnam-ro, Dong-gu, Gwangju 61482 South Korea\", \"price\": None, \"rating\": 4.0},\n",
    "    {\"hotel_id\": 2, \"hotel_name\": \"Dasomchae\", \"description\": \"A cozy hotel offering traditional Korean hospitality.\", \"city\": \"Gwangju\", \"country\": \"South Korea\", \"address\": \"27, Naesang-ro 51beon-gil, Gwangsan-gu, Gwangju 62431 South Korea\", \"price\": None, \"rating\": 4.5},\n",
    "    {\"hotel_id\": 3, \"hotel_name\": \"Brown Dot Hotel\", \"description\": \"A comfortable hotel in a convenient location.\", \"city\": \"Gwangju\", \"country\": \"South Korea\", \"address\": \"5-8, Sangmujungang-ro 38beon-gil, Seo-gu, Gwangju 61963 South Korea\", \"price\": None, \"rating\": 3.5},\n",
    "    {\"hotel_id\": 4, \"hotel_name\": \"Empire Tourist Hotel\", \"description\": \"An affordable hotel for budget-conscious travelers.\", \"city\": \"Gwangju\", \"country\": \"South Korea\", \"address\": \"25, Imbangul-daero 800beon-gil, Gwangsan-gu, Gwangju 62277 South Korea\", \"price\": None, \"rating\": 3.0},\n",
    "    {\"hotel_id\": 5, \"hotel_name\": \"CS Hotel\", \"description\": \"A hotel known for its excellent service.\", \"city\": \"Gwangju\", \"country\": \"South Korea\", \"address\": \"128, Sangmupyeonghwa-ro, Seo-gu, Gwangju 61964 South Korea\", \"price\": None, \"rating\": 3.5},\n",
    "    # Add all other hotel data here as per your list...\n",
    "]\n",
    "\n",
    "# Convert hotels data to DataFrame\n",
    "hotels_df = pd.DataFrame(hotels_data)\n",
    "\n",
    "# Function to generate random user data\n",
    "def generate_user_data(num_users):\n",
    "    user_data = []\n",
    "    for user_id in range(1, num_users + 1):\n",
    "        age = random.randint(18, 70)\n",
    "        gender = random.choice(['M', 'F'])\n",
    "        preferred_location = random.choice(['beach', 'mountain', 'city center', 'countryside'])\n",
    "        preferred_hotel_type = random.choice(['luxury', 'budget', 'boutique'])\n",
    "        \n",
    "        user_data.append({\n",
    "            'user_id': user_id,\n",
    "            'age': age,\n",
    "            'gender': gender,\n",
    "            'preferred_location': preferred_location,\n",
    "            'preferred_hotel_type': preferred_hotel_type\n",
    "        })\n",
    "    return user_data\n",
    "\n",
    "# Function to generate random reviews\n",
    "def generate_review_data(num_reviews, num_users, num_hotels):\n",
    "    review_data = []\n",
    "    for review_id in range(1, num_reviews + 1):\n",
    "        user_id = random.randint(1, num_users)\n",
    "        hotel_id = random.randint(1, num_hotels)\n",
    "        rating = round(random.uniform(1.0, 5.0), 2)\n",
    "        review_txt = f'Review text for review_{review_id}'\n",
    "        \n",
    "        review_data.append({\n",
    "            'review_id': review_id,\n",
    "            'user_id': user_id,\n",
    "            'hotel_id': hotel_id,\n",
    "            'rating': rating,\n",
    "            'review_txt': review_txt\n",
    "        })\n",
    "    return review_data\n",
    "\n",
    "# Generate synthetic data\n",
    "num_users = 100\n",
    "num_reviews = 300\n",
    "num_hotels = len(hotels_data)\n",
    "\n",
    "synthetic_users = generate_user_data(num_users)\n",
    "synthetic_reviews = generate_review_data(num_reviews, num_users, num_hotels)\n",
    "\n",
    "# Convert to DataFrames\n",
    "users_df = pd.DataFrame(synthetic_users)\n",
    "reviews_df = pd.DataFrame(synthetic_reviews)\n",
    "\n",
    "# Save to CSV (optional)\n",
    "users_df.to_csv('synthetic_usereees.csv', index=False)\n",
    "hotels_df.to_csv('synthetic_hoteleees.csv', index=False)\n",
    "reviews_df.to_csv('synthetic_revieweees.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the DataFrames\n",
    "print(\"Users DataFrame:\")\n",
    "print(users_df.head())\n",
    "\n",
    "print(\"\\nHotels DataFrame:\")\n",
    "print(hotels_df.head())\n",
    "\n",
    "print(\"\\nReviews DataFrame:\")\n",
    "print(reviews_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 41.0/45.0 kB 960.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.0/45.0 kB 739.0 kB/s eta 0:00:00\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m db_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecommendation_system\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create a connection to the database\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpymysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_user\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_name\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cursor:\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# Create the users table if it doesn't exist\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pymysql\\connections.py:361\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_key_password, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pymysql\\connections.py:669\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, sock)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_seq_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_server_information()\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_authentication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;66;03m# Send \"SET NAMES\" query on init for:\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;66;03m# - Ensure charaset (and collation) is set to the server.\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;66;03m#   - collation_id in handshake packet may be ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;66;03m# - https://github.com/wagtail/wagtail/issues/9477\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;66;03m# - https://zenn.dev/methane/articles/2023-mysql-collation (Japanese)\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_character_set(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollation)\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pymysql\\connections.py:979\u001b[0m, in \u001b[0;36mConnection._request_authentication\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;66;03m# https://dev.mysql.com/doc/internals/en/successful-authentication.html\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth_plugin_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaching_sha2_password\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 979\u001b[0m     auth_packet \u001b[38;5;241m=\u001b[39m \u001b[43m_auth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaching_sha2_password_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_packet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auth_plugin_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msha256_password\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    981\u001b[0m     auth_packet \u001b[38;5;241m=\u001b[39m _auth\u001b[38;5;241m.\u001b[39msha256_password_auth(\u001b[38;5;28mself\u001b[39m, auth_packet)\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pymysql\\_auth.py:268\u001b[0m, in \u001b[0;36mcaching_sha2_password_auth\u001b[1;34m(conn, pkt)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;28mprint\u001b[39m(conn\u001b[38;5;241m.\u001b[39mserver_public_key\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    267\u001b[0m data \u001b[38;5;241m=\u001b[39m sha2_rsa_encrypt(conn\u001b[38;5;241m.\u001b[39mpassword, conn\u001b[38;5;241m.\u001b[39msalt, conn\u001b[38;5;241m.\u001b[39mserver_public_key)\n\u001b[1;32m--> 268\u001b[0m pkt \u001b[38;5;241m=\u001b[39m \u001b[43m_roundtrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pymysql\\_auth.py:121\u001b[0m, in \u001b[0;36m_roundtrip\u001b[1;34m(conn, send_data)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_roundtrip\u001b[39m(conn, send_data):\n\u001b[0;32m    120\u001b[0m     conn\u001b[38;5;241m.\u001b[39mwrite_packet(send_data)\n\u001b[1;32m--> 121\u001b[0m     pkt \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     pkt\u001b[38;5;241m.\u001b[39mcheck_error()\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pkt\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pymysql\\connections.py:775\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 775\u001b[0m     \u001b[43mpacket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pymysql\\protocol.py:219\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[1;32m--> 219\u001b[0m \u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages\\pymysql\\err.py:150\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mOperationalError\u001b[0m: (1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# Load data from CSV files\n",
    "users_df = pd.read_csv('synthetic_users.csv')\n",
    "reviews_df = pd.read_csv('synthetic_reviews.csv')\n",
    "\n",
    "# Database connection details\n",
    "db_host = 'localhost'\n",
    "db_user = 'root'\n",
    "db_password = 'root'\n",
    "db_name = 'recommendation_system'\n",
    "\n",
    "# Create a connection to the database\n",
    "connection = pymysql.connect(\n",
    "    host=db_host,\n",
    "    user=db_user,\n",
    "    password=db_password,\n",
    "    database=db_name\n",
    ")\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        # Create the users table if it doesn't exist\n",
    "        create_users_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS users (\n",
    "            user_id VARCHAR(255) PRIMARY KEY,\n",
    "            age INT,\n",
    "            gender CHAR(1),\n",
    "            preferred_location VARCHAR(255),\n",
    "            preferred_hotel_type VARCHAR(255)\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_users_table_query)\n",
    "\n",
    "        # Insert data into the users table\n",
    "        for _, row in users_df.iterrows():\n",
    "            insert_user_query = \"\"\"\n",
    "            INSERT INTO users (user_id, age, gender, preferred_location, preferred_hotel_type)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            cursor.execute(insert_user_query, (row['user_id'], row['age'], row['gender'], row['preferred_location'], row['preferred_hotel_type']))\n",
    "        \n",
    "        # Create the reviews table if it doesn't exist\n",
    "        create_reviews_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS reviews (\n",
    "            user_id VARCHAR(255),\n",
    "            avg_rating_given FLOAT,\n",
    "            FOREIGN KEY (user_id) REFERENCES users(user_id)\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_reviews_table_query)\n",
    "\n",
    "        # Insert data into the reviews table\n",
    "        for _, row in reviews_df.iterrows():\n",
    "            insert_review_query = \"\"\"\n",
    "            INSERT INTO reviews (user_id, avg_rating_given)\n",
    "            VALUES (%s, %s)\n",
    "            \"\"\"\n",
    "            cursor.execute(insert_review_query, (row['user_id'], row['avg_rating_given']))\n",
    "\n",
    "    # Commit the transaction\n",
    "    connection.commit()\n",
    "\n",
    "finally:\n",
    "    # Close the connection\n",
    "    connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data from CSV files\n",
    "users_df = pd.read_csv('users.csv')\n",
    "hotels_df = pd.read_csv('hotels_data.csv')\n",
    "reviews_df = pd.read_csv('reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(reviews_df[['user_id', 'hotel_id', 'rating']], reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1890\n",
      "RMSE: 1.1890035761929392\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Use the SVD algorithm\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Test the algorithm on the testset\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Compute and print RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f'RMSE: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 1 and hotel 10: 3.187858311861201\n"
     ]
    }
   ],
   "source": [
    "# Predict the rating for a specific user and hotel\n",
    "user_id = 1  # example user_id\n",
    "hotel_id = 10  # example hotel_id\n",
    "prediction = algo.predict(user_id, hotel_id)\n",
    "print(f'Predicted rating for user {user_id} and hotel {hotel_id}: {prediction.est}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended hotels for user 1: [(1, 3.443091834124955), (5, 3.382604771542623), (3, 3.2211517841606536), (2, 3.1743898571870197), (4, 3.1007577726534046)]\n"
     ]
    }
   ],
   "source": [
    "def recommend_hotels(algo, user_id, n=5):\n",
    "    # Get a list of all hotel_ids\n",
    "    hotel_ids = reviews_df['hotel_id'].unique()\n",
    "    \n",
    "    # Predict ratings for all hotels for the given user\n",
    "    predictions = [algo.predict(user_id, hotel_id).est for hotel_id in hotel_ids]\n",
    "    \n",
    "    # Pair each hotel_id with its predicted rating\n",
    "    hotel_ratings = list(zip(hotel_ids, predictions))\n",
    "    \n",
    "    # Sort the hotels by predicted rating in descending order\n",
    "    hotel_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top N recommended hotels\n",
    "    recommended_hotels = hotel_ratings[:n]\n",
    "    \n",
    "    return recommended_hotels\n",
    "\n",
    "# Get recommendations for a specific user\n",
    "user_id = 1  # example user_id\n",
    "recommendations = recommend_hotels(algo, user_id, n=5)\n",
    "print(f'Top 5 recommended hotels for user {user_id}: {recommendations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1831\n",
      "RMSE: 1.1831275639773278\n",
      "Predicted rating for user 1 and hotel 10: 3.019083333333333\n",
      "Top 5 recommended hotels for existing user 1: ['h_25', 'h_33', 'h_26', 'h_29', 'h_49']\n",
      "Top 5 recommended hotels for new user 101: ['h_25', 'h_33', 'h_26', 'h_29', 'h_49']\n",
      "Content-based recommendations: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load data from CSV files\n",
    "users_df = pd.read_csv('synthetic_users.csv')\n",
    "hotels_df = pd.read_csv('synthetic_hotels.csv')\n",
    "reviews_df = pd.read_csv('synthetic_reviews.csv')\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(reviews_df[['user_id', 'hotel_id', 'rating']], reader)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Use the SVD algorithm\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Test the algorithm on the testset\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Compute and print RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# Predict the rating for a specific user and hotel\n",
    "user_id = 1  # example user_id\n",
    "hotel_id = 10  # example hotel_id\n",
    "prediction = algo.predict(user_id, hotel_id)\n",
    "print(f'Predicted rating for user {user_id} and hotel {hotel_id}: {prediction.est}')\n",
    "\n",
    "# Recommend Hotels for a User\n",
    "def recommend_hotels(algo, user_id, n=5):\n",
    "    # Check if the user_id exists in the training set\n",
    "    try:\n",
    "        # Check if the user exists in the training data's raw to inner mapping\n",
    "        trainset.to_inner_uid(user_id)\n",
    "        # User exists in training data, use collaborative filtering\n",
    "        hotel_ids = reviews_df['hotel_id'].unique()\n",
    "        predictions = [algo.predict(user_id, hotel_id).est for hotel_id in hotel_ids]\n",
    "        hotel_ratings = list(zip(hotel_ids, predictions))\n",
    "        hotel_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        recommended_hotels = hotel_ratings[:n]\n",
    "    except ValueError:\n",
    "        # New user, use content-based or popular hotels recommendation\n",
    "        recommended_hotels = recommend_popular_hotels(n)\n",
    "    return recommended_hotels\n",
    "\n",
    "# Popular Hotels Recommendation\n",
    "def recommend_popular_hotels(n=5):\n",
    "    popular_hotels = reviews_df.groupby('hotel_id').agg({'rating': 'mean', 'review_id': 'count'}).reset_index()\n",
    "    popular_hotels = popular_hotels.sort_values(by=['rating', 'review_id'], ascending=False)\n",
    "    recommended_hotels = popular_hotels.head(n)['hotel_id'].tolist()\n",
    "    return recommended_hotels\n",
    "\n",
    "# Content-Based Recommendation\n",
    "def recommend_hotels_content_based(user_profile, n=5):\n",
    "    filtered_hotels = hotels_df[\n",
    "        (hotels_df['description'].str.contains(user_profile['preferred_hotel_type'], case=False, na=False)) |\n",
    "        (hotels_df['description'].str.contains(user_profile['preferred_location'], case=False, na=False))\n",
    "    ]\n",
    "    filtered_hotels = filtered_hotels.sort_values(by='rating', ascending=False)\n",
    "    recommended_hotels = filtered_hotels.head(n)['hotel_id'].tolist()\n",
    "    return recommended_hotels\n",
    "\n",
    "# Example user profile for content-based recommendation\n",
    "new_user_profile = {'age': 30, 'gender': 'M', 'preferred_location': 'beach', 'preferred_hotel_type': 'luxury'}\n",
    "\n",
    "# Get recommendations for a specific user (existing user example)\n",
    "existing_user_id = 1\n",
    "existing_recommendations = recommend_hotels(algo, existing_user_id, n=5)\n",
    "print(f'Top 5 recommended hotels for existing user {existing_user_id}: {existing_recommendations}')\n",
    "\n",
    "# Get recommendations for a specific user (new user example)\n",
    "new_user_id = 101  # New user (not in training data)\n",
    "new_recommendations = recommend_hotels(algo, new_user_id, n=5)\n",
    "print(f'Top 5 recommended hotels for new user {new_user_id}: {new_recommendations}')\n",
    "\n",
    "# Content-based recommendations for new user profile\n",
    "content_based_recommendations = recommend_hotels_content_based(new_user_profile, n=5)\n",
    "print(f'Content-based recommendations: {content_based_recommendations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svd_model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "reviews_df = pd.read_csv('synthetic_reviews.csv')\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(reviews_df[['user_id', 'hotel_id', 'rating']], reader)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Use the SVD algorithm\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(algo, 'svd_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests) (2023.11.17)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.tripadvisor.com/Hotels'\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = soup.find_all('img', {'class': 'hotel_image_class'})  # Replace 'hotel_image_class' with the actual class name of the images\n",
    "image_urls = [img['src'] for img in images if 'src' in img.attrs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('hotel_images', exist_ok=True)\n",
    "\n",
    "for i, url in enumerate(image_urls):\n",
    "    image_response = requests.get(url)\n",
    "    with open(f'hotel_images/hotel_image_{i}.jpg', 'wb') as file:\n",
    "        file.write(image_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def fetch_hotel_images(url):\n",
    "    # Step 1: Send a request to the website\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    # Step 2: Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Step 3: Find and extract image URLs\n",
    "    images = soup.find_all('img', {'class': 'hotel_image_class'})  # Adjust the class name as needed\n",
    "    image_urls = [img['src'] for img in images if 'src' in img.attrs]\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "def download_images(image_urls):\n",
    "    os.makedirs('hotel_images', exist_ok=True)\n",
    "\n",
    "    for i, url in enumerate(image_urls):\n",
    "        try:\n",
    "            image_response = requests.get(url)\n",
    "            with open(f'hotel_images/hotel_image_{i}.jpg', 'wb') as file:\n",
    "                file.write(image_response.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download image {url}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://www.tripadvisor.com/Hotels'\n",
    "    image_urls = fetch_hotel_images(url)\n",
    "    if image_urls:\n",
    "        download_images(image_urls)\n",
    "    else:\n",
    "        print(\"No images found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (4.21.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.18)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from selenium) (0.25.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from trio~=0.17->selenium) (1.2.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dslab\\anaconda3\\envs\\myenv\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "\n",
    "def fetch_hotel_images(url):\n",
    "    # Set up Selenium WebDriver\n",
    "    driver = webdriver.Chrome()  # Ensure you have the ChromeDriver installed and in your PATH\n",
    "    driver.get(url)\n",
    "\n",
    "    # Allow time for the page to load\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Find image elements\n",
    "    images = driver.find_elements(By.TAG_NAME, 'img')\n",
    "\n",
    "    # Extract image URLs\n",
    "    image_urls = [img.get_attribute('src') for img in images if img.get_attribute('src')]\n",
    "\n",
    "    # Print the number of images found\n",
    "    print(f\"Number of images found: {len(image_urls)}\")\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "def download_images(image_urls):\n",
    "    os.makedirs('hotel_images', exist_ok=True)\n",
    "\n",
    "    for i, url in enumerate(image_urls):\n",
    "        try:\n",
    "            image_response = requests.get(url)\n",
    "            with open(f'hotel_images/hotel_image_{i}.jpg', 'wb') as file:\n",
    "                file.write(image_response.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download image {url}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://www.tripadvisor.com/Hotels'\n",
    "    image_urls = fetch_hotel_images(url)\n",
    "    if image_urls:\n",
    "        download_images(image_urls)\n",
    "    else:\n",
    "        print(\"No images found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3528830763.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    -- Log into MySQL\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Database connection configuration\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'root',\n",
    "    'database': 'recommendation_system'\n",
    "}\n",
    "\n",
    "# Connect to the database\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "\n",
    "# Define the query to select the data from the table\n",
    "query = \"SELECT * FROM hotels\"\n",
    "\n",
    "# Use pandas to read the data from the database\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Specify the path where you want to save the CSV file\n",
    "csv_file_path = 'output.csv'\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "print(f\"Data exported to {csv_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
